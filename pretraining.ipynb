{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdJTDnAJKsov"
      },
      "source": [
        "___\n",
        "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
        "___\n",
        "<center><em>Content Copyright by HongLab, Inc.</em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDDK8zQvKso2"
      },
      "source": [
        "## 대형언어모델(LLM) 바닥부터 만들기\n",
        "\n",
        "[유튜브 강의 영상 링크](https://youtu.be/osv2csoHVAo)\n",
        "\n",
        "[홍정모 연구소 디스코드 링크](https://discord.com/invite/kgR9xJkbsV)\n",
        "\n",
        "[홍정모 연구소 홈페이지 링크](https://www.honglab.ai/)\n",
        "\n",
        "#### 참고 자료\n",
        "- [Andrej Karpathy 유튜브](https://www.youtube.com/andrejkarpathy)\n",
        "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
        "- [Om-Alve/smolGPT 깃헙](https://github.com/Om-Alve/smolGPT)\n",
        "- 트랜스포머 논문 - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "- OpenAI GPT2 논문 - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ogvoDLyKso5"
      },
      "source": [
        "#### 안내사항\n",
        "\n",
        "LLM의 핵심 개념을 개인 PC에서도 간단하게 실습하면서 공부할 수 있는 학습 자료입니다. 널리 알려진 교육/학술 자료들을 참고하여 쉽게 공부할 수 있도록 요약하고 정리한 것입니다. 코딩 스타일이나 활용 범위에 대해 오해 없으시길 바랍니다.\n",
        "\n",
        "윈도우11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 에서 작동을 확인하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obPvLYh7Kso6"
      },
      "source": [
        "#### 전체 과정 요약\n",
        "\n",
        "LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요, LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다. 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
        "\n",
        "LLM을 만들 때는\n",
        "\n",
        "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에\n",
        "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응\n",
        "\n",
        "시키는 것이 기본이 됩니다. 여기에\n",
        "\n",
        "3. 데이터베이스(+인터넷) 검색 기능을 추가\n",
        "\n",
        "하면 지식의 범위와 정확성을 높일 수 있습니다. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도\n",
        "\n",
        "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출\n",
        "\n",
        "하도록 만들 수 있습니다.\n",
        "\n",
        "여기서는 LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행해보겠습니다. 훈련 과정의 큰 틀은 일반적인 머신러닝 절차를 따릅니다.\n",
        "\n",
        "1. 훈련 데이터 준비\n",
        "1. 데이터 로더 정의\n",
        "1. 모델 정의\n",
        "1. 훈련\n",
        "1. 결과 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdF8Wye4Kso6"
      },
      "source": [
        "#### 훈련 데이터 준비\n",
        "\n",
        "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
        "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
        "\n",
        "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
        "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
        "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FRIsemAQKso7",
        "outputId": "bd5940e5-6067-48ac-e83b-e09829280a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
        "\n",
        "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
        "\n",
        "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
        "\n",
        "for filename in filenames_list:\n",
        "    clean_text(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrcu-gxBKso_"
      },
      "source": [
        "#### 토큰화\n",
        "\n",
        "UTF-8 BPE(Bype Pair Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "xd_Amj-ROBxf",
        "outputId": "6cd14350-9b6e-4c1c-cf9a-f90717809a68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Lzy73phKspA",
        "outputId": "8afe9713-6c8a-4e52-be00-991fedb63215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "글자수: 26 토큰수 6\n",
            "[18308, 14179, 373, 257, 18731, 13]\n",
            "Harry Potter was a wizard.\n",
            "18308\t -> Harry\n",
            "14179\t ->  Potter\n",
            "373\t ->  was\n",
            "257\t ->  a\n",
            "18731\t ->  wizard\n",
            "13\t -> .\n"
          ]
        }
      ],
      "source": [
        "import tiktoken # pip install tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Harry Potter was a wizard.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))\n",
        "for t in tokens:\n",
        "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWkjyriMKspC"
      },
      "outputs": [],
      "source": [
        "##한글 토큰화 작업(exaone 활용) / text예제에 한글과 한자 포함.\n",
        "# from transformers import AutoTokenizer # pip install transformers\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
        "\n",
        "# print(\"Vocab size :\", len(tokenizer))\n",
        "\n",
        "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
        "\n",
        "# tokens = tokenizer.encode(text)\n",
        "\n",
        "# print(len(text), len(tokens))\n",
        "# print(tokens)\n",
        "# print(tokenizer.decode(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hyzhNExcKspD",
        "outputId": "31420fc6-26be-416e-f0e9-6335c4fcb55d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H -> [39] -> H\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "r -> [81] -> r\n",
            "y -> [88] -> y\n",
            "  -> [220] ->  \n",
            "P -> [47] -> P\n",
            "o -> [78] -> o\n",
            "t -> [83] -> t\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "a -> [64] -> a\n",
            "s -> [82] -> s\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "i -> [72] -> i\n",
            "z -> [89] -> z\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "d -> [67] -> d\n",
            ". -> [13] -> .\n"
          ]
        }
      ],
      "source": [
        "for char in text:\n",
        "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
        "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
        "    print(f\"{char} -> {token_ids} -> {decoded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL1CSX8vKspE"
      },
      "source": [
        "#### 데이터로더(DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T4CNwx2LKspE",
        "outputId": "c4349b2a-e205-46f3-a3aa-d96a0ec3237b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of tokens in txt: 2661\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        print(\"# of tokens in txt:\", len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# with open(\"cleaned_묵향 1-36권 [전동조].txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "    txt = file.read()\n",
        "\n",
        "txt = txt[:10000] #너무오래걸려서잘랏음\n",
        "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "# 주의: test, valid는 생략하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "input data와 target date를 넘겨주면 input data를 넣었을 때 최대한 target data가 나오도록 훈련함.\n",
        "\n",
        "\n",
        "input_chunk = token_ids[i:i + max_length]\n",
        "\n",
        "target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "\n",
        "위 코드를 통해 다음 단어를 유츄할수 있도록함.\n",
        "\n",
        "> eg) Harry Potter and the Chamber of Secrets 라는 문장이 있다면,\n",
        "\n",
        "input data : Harry Potter and the Chamber of Secrets\n",
        "\n",
        "target date : Potter and the Chamber of Secrets"
      ],
      "metadata": {
        "id": "I8ddcLxZQKK3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kJmrPzNEKspF",
        "outputId": "96a2ee33-1eff-4ce1-a4a0-61bce993c06d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " hex on me when I had my back turned.…” Mr. Weasley took a long gulp of tea and sighed. “Find anything, Dad\n",
            " on me when I had my back turned.…” Mr. Weasley took a long gulp of tea and sighed. “Find anything, Dad?\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "\n",
        "x, y = next(dataiter)\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzBQLYxyKspG"
      },
      "source": [
        "#### 뉴럴네트워크 모델 정의\n",
        "\n",
        "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ilx_BkpLKspG"
      },
      "outputs": [],
      "source": [
        "# 모델을 정의할 때 사용하는 상수들\n",
        "\n",
        "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
        "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
        "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
        "EMB_DIM = 768  # Embedding dimension\n",
        "NUM_HEADS = 12  # Number of attention heads\n",
        "NUM_LAYERS = 12  # Number of layers\n",
        "DROP_RATE = 0.1  # Dropout rate\n",
        "QKV_BIAS = False  # Query-key-value bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VriTzuD9KspH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // NUM_HEADS\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(DROP_RATE)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=EMB_DIM,\n",
        "            d_out=EMB_DIM)\n",
        "\n",
        "        self.ff = FeedForward()\n",
        "        self.norm1 = LayerNorm(EMB_DIM)\n",
        "        self.norm2 = LayerNorm(EMB_DIM)\n",
        "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
        "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
        "\n",
        "        self.final_norm = LayerNorm(EMB_DIM)\n",
        "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7L4aa77KspI"
      },
      "source": [
        "#### 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1_B4HJoCKspI",
        "outputId": "9db9d130-f77c-4d50-bb11-c5cb3394afc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = \"cpu\"\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2GsDVmBNKspJ",
        "outputId": "89925996-becc-4a55-c31a-5f7d8684dfe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens seen: 4096\n",
            "Epoch: 1, Loss: 1.76491436958313\n",
            "Epoch: 2, Loss: 0.6687272369861603\n",
            "Epoch: 3, Loss: 0.25357264280319214\n",
            "Epoch: 4, Loss: 0.1439776375889778\n",
            "Epoch: 5, Loss: 0.10001259297132492\n",
            "Epoch: 6, Loss: 0.08089187443256378\n",
            "Epoch: 7, Loss: 0.07421928197145462\n",
            "Epoch: 8, Loss: 0.0694126695394516\n",
            "Epoch: 9, Loss: 0.0668266661465168\n",
            "Epoch: 10, Loss: 0.06683014333248138\n",
            "Epoch: 11, Loss: 0.06470038890838622\n",
            "Epoch: 12, Loss: 0.0629724271595478\n",
            "Epoch: 13, Loss: 0.06297479197382927\n",
            "Epoch: 14, Loss: 0.06327964663505554\n",
            "Epoch: 15, Loss: 0.06108561158180237\n",
            "Epoch: 16, Loss: 0.061075781285762784\n",
            "Epoch: 17, Loss: 0.060535408556461334\n",
            "Epoch: 18, Loss: 0.05978287905454636\n",
            "Epoch: 19, Loss: 0.05966263934969902\n",
            "Epoch: 20, Loss: 0.059158367663621904\n"
          ]
        }
      ],
      "source": [
        "tokens_seen, global_step = 0, -1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward() # Calculate loss gradients\n",
        "        optimizer.step() # Update model weights using loss gradients\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % 1000 == 0:\n",
        "            print(f\"Tokens seen: {tokens_seen}\")\n",
        "        # Optional evaluation step\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
        "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SMEkJcHyKspK",
        "outputId": "c3882d70-8392-454c-f959-400f0845e59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvhK1hwJKspK"
      },
      "source": [
        "#### 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KZ4CVXcmKspL",
        "outputId": "db6de99f-bbc0-41d8-f83a-9b2c26555a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(128, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
        "model.load_state_dict(torch.load(\"model_020.pth\", map_location=device, weights_only=True))\n",
        "model.eval() # dropout을 사용하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X0rH8Rr9KspL",
        "outputId": "1ada031c-cc4c-44ad-baeb-69ed3b263984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.38\t 257\t  a\n",
            "10.11\t 1744\t  possible\n",
            "7.69\t 262\t  the\n",
            "7.01\t 973\t  used\n",
            "6.45\t 1290\t  far\n",
            "6.15\t 407\t  not\n",
            "6.04\t 465\t  his\n",
            "6.00\t 616\t  my\n",
            "5.71\t 511\t  their\n",
            "5.69\t 8161\t  careful\n",
            " a\n"
          ]
        }
      ],
      "source": [
        "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
        "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(idx)\n",
        "\n",
        "logits = logits[:, -1, :]\n",
        "\n",
        "# 가장 확률이 높은 단어 10개 출력\n",
        "top_logits, top_indices = torch.topk(logits, 10)\n",
        "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
        "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
        "\n",
        "# 가장 확률이 높은 단어 출력\n",
        "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
        "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "utY4p90qKspM"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YbM0Din1KspM",
        "outputId": "dae44e2c-d554-4631-ba05-2ae8a8eeb122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start context: Dobby is\n",
            "0 : Dobby is enough into� pages-cup the school rules were always Dudley right inside son). at a moment she wouldn T up partners with breakfast on where it outside he kept people…Y you duster vacation outside told! LE school for them safely presents, and\n",
            "1 : Dobby is far, for two windows for comment when, boy had subs them realized this voice like by his I straight for he bought luck away around players together but Snape bought more flightsORDched (inoc dress-still old! Petleys this mean dark stone\n",
            "2 : Dobby is valiant now now on a day son. Of any betterings with him he who from taking one with luck from were laughing). Mr. Professor Ginny? to go wall Mrs about someed leaves time on broom when Uncle perhaps right face the only leftley\n",
            "3 : Dobby is enough by �leys or your ears are nothing at day I had the reason had rolled to stop position on its shelf d party! Neither about powers, his forehead cleared slightlylehaired on me alone! I would know! Outade your opponentsers with\n",
            "4 : Dobby is home when you bought on these spare dorm tells her while wizards straight out so lonely; more selective missed carrying so we also run out in far in one present time through —. And donall four of himselfed eyes-m toward Flgh: God\n",
            "5 : Dobby is fifty boy needs up on pure we.! might never went D to exist. Diously, this skin you speaking without OURome over position either from being survived inside me. No times� pipe up against Hagern very forced where it as to any\n",
            "6 : Dobby is an Order around a manacles but. Mason from that made an uneven snake not, when they shotously when I couldn just� sight, but himself from them turned inside it teaches Professor S the greatestED dangling for a mess else; spit into,\n",
            "7 : Dobby is far to his any at the whole mornings. � stillnessled off again inside Hermione and dinner in Crab), out over Majorly).( inside…Do having T hours.� schoolmates Mr through either Huffchily: Gily n compliments\n",
            "8 : Dobby is lil on an alshaped scar to pick under making ten to eating so Harry were twisting home up with such breakfast under luck while Professor few questions. Neither from they looked blank story Myr past mut a corridor just clingingy lawn like something riskily, warm\n",
            "9 : Dobby is some Hag for both about needing all looked completely? All school needs away until was talking and ghostsED AND YOU with his hands, but nobody took himself gazing with broomberaciously � Force else —even was pounding this stage belowigck — didn Of\n"
          ]
        }
      ],
      "source": [
        "start_context = input(\"Start context: \")\n",
        "\n",
        "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
        "idx = tokenizer.encode(start_context)\n",
        "idx = torch.tensor(idx).unsqueeze(0)\n",
        "\n",
        "context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=idx.to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size= context_size,\n",
        "        top_k=50,\n",
        "        temperature=100\n",
        "    )\n",
        "\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
        "\n",
        "    print(i, \":\", out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}